\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{berlyne1970novelty}
\citation{hargreaves1984effects}
\citation{sluckin1980liking}
\citation{manovich2007comes}
\citation{doyle2007new}
\citation{marvelmultiverse}
\citation{spiderman}
\citation{2016film}
\citation{wiki:transf_work}
\citation{wiki:fandom}
\citation{ao3stats}
\citation{thomas2011fanfiction}
\citation{black2006language}
\citation{LIT:LIT12061}
\citation{hills2015expertise}
\citation{zhaopredicting}
\citation{yung2013market}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\citation{elgammal2015quantifying}
\citation{wang2013quantifying}
\citation{2017arXiv170704239I}
\citation{sreenivasan2013quantitative}
\citation{jurafsky2000speech}
\citation{Ponte:1998:LMA:290941.291008}
\citation{singhal2017pivoted}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:fandom_size}{{1a}{2}{Number of fanfictions in each fandom\relax }{figure.caption.1}{}}
\newlabel{sub@fig:fandom_size}{{a}{2}{Number of fanfictions in each fandom\relax }{figure.caption.1}{}}
\newlabel{fig:fic_time_dist}{{1b}{2}{Number of fanfictions published each month\relax }{figure.caption.1}{}}
\newlabel{sub@fig:fic_time_dist}{{b}{2}{Number of fanfictions published each month\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Statistics of the size and temporal distribution of our fanfiction dataset\relax }}{2}{figure.caption.1}}
\newlabel{fig:stats_size_time}{{1}{2}{Statistics of the size and temporal distribution of our fanfiction dataset\relax }{figure.caption.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Results}{2}{section.2}}
\newlabel{fig:length_dist}{{2a}{3}{Length distribution of fictions. For multi-chapter fictions, we show the average length of each chapter.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:length_dist}{{a}{3}{Length distribution of fictions. For multi-chapter fictions, we show the average length of each chapter.\relax }{figure.caption.2}{}}
\newlabel{fig:kudos_dist}{{2b}{3}{Log-log cumulative distribution of Kudos. For multi-chapter fictions, we use the average number of Kudos per chapter.\relax }{figure.caption.2}{}}
\newlabel{sub@fig:kudos_dist}{{b}{3}{Log-log cumulative distribution of Kudos. For multi-chapter fictions, we use the average number of Kudos per chapter.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Statistics on the length and Kudos of fictions\relax }}{3}{figure.caption.2}}
\newlabel{fig:stats_len_kudos}{{2}{3}{Statistics on the length and Kudos of fictions\relax }{figure.caption.2}{}}
\newlabel{fig:unigram_cos}{{3a}{3}{Negative correlation between novelty and Kudos, using the unigram model. As the cosine distance between a fiction and the ``average" of previous fictions increase, the average z-score of Kudos decrease.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:unigram_cos}{{a}{3}{Negative correlation between novelty and Kudos, using the unigram model. As the cosine distance between a fiction and the ``average" of previous fictions increase, the average z-score of Kudos decrease.\relax }{figure.caption.3}{}}
\newlabel{fig:lda_cos}{{3b}{3}{Negative correlation between novelty and Kudos, using topic modeling. The cosine distance is calculated between the topic distribution of a fiction and the average of topic distribution of previous fictions. As cosine distance increases, the average z-score of Kudos decrease.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:lda_cos}{{b}{3}{Negative correlation between novelty and Kudos, using topic modeling. The cosine distance is calculated between the topic distribution of a fiction and the average of topic distribution of previous fictions. As cosine distance increases, the average z-score of Kudos decrease.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Relation between novelty and Kudos on a document level\relax }}{3}{figure.caption.3}}
\newlabel{fig:novelty_kudos_doc}{{3}{3}{Relation between novelty and Kudos on a document level\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Novelty doesn't make fictions successful}{3}{subsection.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methods}{3}{section.3}}
\newlabel{sec:methods}{{3}{3}{Methods}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data}{3}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Tag novelty and Kudos\relax }}{4}{figure.caption.4}}
\newlabel{fig:tag_novelty}{{4}{4}{Tag novelty and Kudos\relax }{figure.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Metadata of the writings\relax }}{4}{table.caption.5}}
\newlabel{tab:metadata}{{1}{4}{Metadata of the writings\relax }{table.caption.5}{}}
\citation{gales1995good}
\bibstyle{acm}
\bibdata{main}
\bibcite{berlyne1970novelty}{1}
\bibcite{black2006language}{2}
\bibcite{marvelmultiverse}{3}
\bibcite{doyle2007new}{4}
\bibcite{elgammal2015quantifying}{5}
\bibcite{wiki:transf_work}{6}
\bibcite{gales1995good}{7}
\bibcite{hargreaves1984effects}{8}
\bibcite{hills2015expertise}{9}
\bibcite{2017arXiv170704239I}{10}
\bibcite{jurafsky2000speech}{11}
\bibcite{LIT:LIT12061}{12}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Language model}{5}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Regression}{5}{subsection.3.3}}
\bibcite{manovich2007comes}{13}
\bibcite{ao3stats}{14}
\bibcite{Ponte:1998:LMA:290941.291008}{15}
\bibcite{sluckin1980liking}{16}
\bibcite{sreenivasan2013quantitative}{17}
\bibcite{thomas2011fanfiction}{18}
\bibcite{wang2013quantifying}{19}
\bibcite{wiki:fandom}{20}
\bibcite{2016film}{21}
\bibcite{fanfiction.net}{22}
\bibcite{spiderman}{23}
\bibcite{yung2013market}{24}
\bibcite{zhaopredicting}{25}
