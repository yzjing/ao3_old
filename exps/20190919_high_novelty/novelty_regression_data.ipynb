{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import colors\n",
    "from labMTsimple.storyLab import *\n",
    "from scipy.stats import entropy\n",
    "import nsb_entropy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take 5% novelty fics from each fandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_path = '../../data/tfidf_toprev_conlen_full_v2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_path = '../../data/lda_toprev_with_dist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "fandom_list = ['harry_potter',\n",
    " 'dcu',\n",
    "  'doctor_who_&_related_fandoms',\n",
    " 'star_wars_all_media_types',\n",
    " 'arthurian_mythology_&_related_fandoms',\n",
    " 'haikyuu',\n",
    " 'kuroko_no_basuke',\n",
    " 'hamilton_miranda',\n",
    " 'dragon_age_all_media_types',\n",
    " 'the_walking_dead_&_related_fandoms',\n",
    " 'buffy_the_vampire_slayer',\n",
    " 'les_miserables_all_media_types',\n",
    " 'naruto',\n",
    " 'tolkien_j_r_r_works_&_related_fandoms',\n",
    " 'shakespare_william_works',\n",
    " 'hetalia_axis_powers',\n",
    " 'attack_on_titan',\n",
    " 'ms_paint_adventures',\n",
    " 'bishoujo_senshi_sailor_moon',\n",
    " 'one_direction',\n",
    " 'sherlock_holmes_&_related_fandoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    " 'supernatural',\n",
    " 'marvel',\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_rel(field):\n",
    "    # Isolate the first relationship listed for the work\n",
    "    try:\n",
    "        return field.split(',')[0]\n",
    "    except:\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_major_rel(df):\n",
    "    df['Relationship'] = df.apply(lambda row: first_rel(row['Relationship']), axis=1)\n",
    "    counts = df['Relationship'].value_counts()\n",
    "    return counts.keys()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_today(cell):\n",
    "    try:\n",
    "        y, m, d = cell.split('-')\n",
    "        return abs(date.today() - date(int(y), int(m), int(d))).days\n",
    "    except:\n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dfs(df):\n",
    "    \n",
    "    # normalization of the success field\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df['Hits'].fillna(0, inplace=True)\n",
    "    df['Kudos'].fillna(0, inplace=True)\n",
    "    df['Bookmarks'].fillna(0, inplace=True)\n",
    "    df['Comments'].fillna(0, inplace=True)\n",
    "\n",
    "    # normalize by chapter number\n",
    "    df['Kudos'] = df['Kudos']/df['Chapters'] \n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df['Kudos'].dropna()\n",
    "\n",
    "    df['Hits'] = df['Hits']/df['Chapters']\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df['Hits'].dropna()\n",
    "\n",
    "    df['Bookmarks'] = df['Bookmarks']/df['Chapters']\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df['Bookmarks'].dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dfs(data_path, file_suffix, novelty_field, top_tail_option):\n",
    "    df_all = []\n",
    "    if top_tail_option == 'top':\n",
    "        ascending_flag = False\n",
    "    elif top_tail_option == 'tail':\n",
    "        ascending_flag = True\n",
    "        \n",
    "    for i,fandom in enumerate(fandom_list):\n",
    "        df = pd.read_csv(os.path.join(data_path,fandom + file_suffix), sep = '\\t', \n",
    "                         error_bad_lines=False,  engine='python')\n",
    "        if data_path == 'tfidf_path':\n",
    "            df_topic = pd.read_csv(\n",
    "                os.path.join(lda_path, fandom + '_temporal_lda_jsd_toprev_full_with_dist.tsv'), sep='\\t'\n",
    "            )\n",
    "            df = pd.merge(df, df_topic, on=['AdditionalTags', 'ArchiveWarnings', 'Author', 'Bookmarks', 'Category',\\\n",
    "                         'ChapterIndex', 'Chapters' ,'Characters','Comments' ,'CompleteDate',\\\n",
    "                         'Fandoms', 'Hits' ,'Kudos', 'Language', 'Notes' ,'PublishDate' ,'Rating',\\\n",
    "                         'Relationship' ,'Summary' ,'Title' ,'URL' ,'UpdateDate' ,'Words'], how='inner')\n",
    "\n",
    "        df['Fandoms'] = fandom\n",
    "        df = df.sort_values(by=novelty_field, ascending=ascending_flag).head(int(len(df)*0.05))\n",
    "       \n",
    "        df = normalize_dfs(df)\n",
    "        \n",
    "        # Add relationship control variable\n",
    "        freq_rel = find_major_rel(df)\n",
    "        df['Relationship'] = df['Relationship'].apply(lambda x: first_rel(x))\n",
    "        df['Freq_relationship'] = df['Relationship'].apply(lambda x: 1 if x in freq_rel else 0)\n",
    "        del df['Relationship']\n",
    "        # calculate topic entropy\n",
    "        df['Topic_entropy'] = df.apply(lambda row: entropy(eval(row['Dist'])), axis=1)\n",
    "        df_all.append(df)\n",
    "    df_all = pd.concat(df_all)\n",
    "#     df_all.to_csv(top_tail_option + '_' + novelty_field  + '_' + 'novelty_to_join_text.tsv', sep='\\t')\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_tail_option='top'\n",
    "novelty_field = 'JSD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 5685: unexpected end of data\n"
     ]
    }
   ],
   "source": [
    "df_all = preprocess_dfs(data_path = lda_path, file_suffix = '_temporal_lda_jsd_toprev_full_with_dist.tsv',\n",
    "                                       novelty_field = novelty_field, top_tail_option=top_tail_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1771    This is an emergency.\\xc2\\xa0 Repeat.\\xc2\\xa0 ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(1).Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "labMT,labMTvector,labMTwordList = emotionFileReader(stopval=0.0, lang='english',returnVector=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sent(text, labMT, labMTvector, labMTwordList):\n",
    "    sampleValence,sampleFvec = emotion(text, labMT, shift=True, happsList=labMTvector)\n",
    "    sampleStoppedVec = stopper(sampleFvec, labMTvector, labMTwordList, stopVal=1.0)\n",
    "    sampleValence = emotionV(sampleStoppedVec, labMTvector)\n",
    "    return sampleValence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Sentiment'] = df_all.apply(lambda row: eval_sent(row['Text'], labMT, labMTvector, labMTwordList), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Sentiment'] = df_all['Sentiment'] -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 6.0000e+00, 5.7500e+02, 1.3323e+04, 2.7600e+03]),\n",
       " array([-6.        , -5.20922477, -4.41844954, -3.62767431, -2.83689908,\n",
       "        -2.04612385, -1.25534862, -0.46457339,  0.32620183,  1.11697706,\n",
       "         1.90775229]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_all['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(min_df=2, max_df=0.8, stop_words='english')\n",
    "vectorizer = tf.fit(df.Text.tolist()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = vectorizer.transform(df.Text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16665x67943 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4356147 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Word_vectors'] = df.apply(lambda row: transformed[row.name], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nsb(row):\n",
    "    vec = np.array(row['Word_vectors'].todense())\n",
    "    K = vec.size\n",
    "    return nsb_entropy.S(nsb_entropy.make_nxkx(vec, K), vec.sum(), K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Word_entropy'] = df.apply(lambda row: compute_nsb(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete unnecessary fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_all['Language']\n",
    "del df_all['Notes']\n",
    "del df_all['Summary']\n",
    "del df_all['Title']\n",
    "del df_all['URL']\n",
    "del df_all['AdditionalTags']\n",
    "del df_all['Characters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up, create categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Chapters'] = df_all['Chapters'].fillna(0)\n",
    "df_all.Words = df_all.Words/df_all.Chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Category'].fillna('Unknown', inplace=True)\n",
    "df_all['Category_F_F'] = df_all['Category'].apply(lambda x: 1 if 'F/F' in x else 0)\n",
    "df_all['Category_F_M'] = df_all['Category'].apply(lambda x: 1 if 'F/M' in x else 0)\n",
    "df_all['Category_Gen'] = df_all['Category'].apply(lambda x: 1 if 'Gen' in x else 0)\n",
    "df_all['Category_M_M'] = df_all['Category'].apply(lambda x: 1 if 'M/M' in x else 0)\n",
    "df_all['Category_Multi'] = df_all['Category'].apply(lambda x: 1 if 'Multi' in x else 0)\n",
    "df_all['Category_Other'] = df_all['Category'].apply(lambda x: 1 if 'Other' in x else 0)\n",
    "df_all['Category_Unknown'] = df_all['Category'].apply(lambda x: 1 if 'Unknown' in x else 0)\n",
    "del df_all['Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ArchiveWarnings_underage'] = df_all['ArchiveWarnings'].apply(lambda x: 1 if 'Underage' in x else 0)\n",
    "df_all['ArchiveWarnings_death'] = df_all['ArchiveWarnings'].apply(lambda x: 1 if 'Major Character Death' in x else 0)\n",
    "df_all['ArchiveWarnings_choose_no'] = df_all['ArchiveWarnings'].apply(lambda x: 1 if 'Creator Chose Not To Use Archive Warnings' in x else 0)\n",
    "df_all['ArchiveWarnings_no_apply'] = df_all['ArchiveWarnings'].apply(lambda x: 1 if 'No Archive Warnings Apply' in x else 0)\n",
    "df_all['ArchiveWarnings_violence'] = df_all['ArchiveWarnings'].apply(lambda x: 1 if 'Graphic Depictions Of Violence' in x else 0)\n",
    "df_all['ArchiveWarnings_noncon'] = df_all['ArchiveWarnings'].apply(lambda x: 1 if 'Rape/Non-Con' in x else 0)\n",
    "\n",
    "del df_all['ArchiveWarnings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all = df_all[df_all['ArchiveWarnings_blood'] != 1]\n",
    "# df_all = df_all[df_all['ArchiveWarnings_none'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['ChapterIndex'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Rating_E'] = df_all['Rating'].apply(lambda x: 1 if x == 'Explicit' else 0)\n",
    "df_all['Rating_G'] = df_all['Rating'].apply(lambda x: 1 if x == 'General Audiences' else 0)\n",
    "df_all['Rating_M'] = df_all['Rating'].apply(lambda x: 1 if x == 'Mature' else 0)\n",
    "df_all['Rating_N'] = df_all['Rating'].apply(lambda x: 1 if x == 'Not Rated' else 0)\n",
    "df_all['Rating_T'] = df_all['Rating'].apply(lambda x: 1 if x == 'Teen And Up Audiences' else 0)\n",
    "del df_all['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['index', 'Author', 'Bookmarks', 'ChapterIndex', 'Chapters',\n",
       "       'Comments', 'CompleteDate', 'Fandoms', 'Hits', 'Kudos',\n",
       "       'PublishDate', 'Text', 'UpdateDate', 'Words', 'Dist', 'JSD',\n",
       "       'Freq_relationship', 'Topic_entropy', 'Sentiment', 'Category_F_F',\n",
       "       'Category_F_M', 'Category_Gen', 'Category_M_M', 'Category_Multi',\n",
       "       'Category_Other', 'Category_Unknown', 'ArchiveWarnings_underage',\n",
       "       'ArchiveWarnings_death', 'ArchiveWarnings_choose_no',\n",
       "       'ArchiveWarnings_no_apply', 'ArchiveWarnings_violence',\n",
       "       'ArchiveWarnings_noncon', 'Rating_E', 'Rating_G', 'Rating_M',\n",
       "       'Rating_N', 'Rating_T'], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Fandom_harry_potter'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'harry_potter' else 0)\n",
    "df_all['Fandom_dcu'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'dcu' else 0)\n",
    "df_all['Fandom_doctor_who'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'doctor_who_&_related_fandoms' else 0)\n",
    "df_all['Fandom_star_wars'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'star_wars_all_media_types' else 0)\n",
    "df_all['Fandom_arthurian'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'arthurian_mythology_&_related_fandoms' else 0)\n",
    "df_all['Fandom_supernatural'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'supernatural' else 0)\n",
    "df_all['Fandom_haikyuu'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'haikyuu' else 0)\n",
    "df_all['Fandom_kuroko_no_basuke'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'kuroko_no_basuke' else 0)\n",
    "df_all['Fandom_hamilton_miranda'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'hamilton_miranda' else 0)\n",
    "df_all['Fandom_dragon_age'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'dragon_age_all_media_types' else 0)\n",
    "df_all['Fandom_the_walking_dead'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'the_walking_dead_&_related_fandoms' else 0)\n",
    "df_all['Fandom_buffy'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'buffy_the_vampire_slayer' else 0)\n",
    "df_all['Fandom_les_miserables'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'les_miserables_all_media_types' else 0)\n",
    "df_all['Fandom_naruto'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'naruto' else 0)\n",
    "df_all['Fandom_tolkien'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'tolkien_j_r_r_works_&_related_fandoms' else 0)\n",
    "df_all['Fandom_shakespare'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'shakespare_william_works' else 0)\n",
    "df_all['Fandom_hetalia'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'hetalia_axis_powers' else 0)\n",
    "df_all['Fandom_attack_on_titan'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'attack_on_titan' else 0)\n",
    "df_all['Fandom_ms_paint_adventures'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'ms_paint_adventures' else 0)\n",
    "df_all['Fandom_marvel'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'marvel' else 0)\n",
    "df_all['Fandom_sailor_moon'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'bishoujo_senshi_sailor_moon' else 0)\n",
    "df_all['Fandom_one_direction'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'one_direction' else 0)\n",
    "df_all['Fandom_sherlock'] = df_all['Fandoms'].apply(lambda x: 1 if x == 'sherlock_holmes_&_related_fandoms' else 0)\n",
    "\n",
    "del df_all['Fandoms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute \"history\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['CompleteDate'] = df_all.apply(lambda row: date_today(row['CompleteDate']), axis = 1)\n",
    "df_all['UpdateDate'] = df_all.apply(lambda row: date_today(row['UpdateDate']), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['PublishDate'] = df_all.apply(lambda row: date_today(row['UpdateDate']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_history(field_list):\n",
    "    field_list = [10000000 if np.isnan(x) else x for x in field_list]\n",
    "    return np.amin(field_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['history'] = df_all.apply(lambda row: find_history([row['PublishDate'], row['CompleteDate'], row['UpdateDate']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_all['PublishDate']\n",
    "del df_all['CompleteDate']\n",
    "del df_all['UpdateDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.rename(columns = {'history':'History', 'Cos': 'Term_novelty', 'JSD': 'Topic_novelty'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Author</th>\n",
       "      <th>Bookmarks</th>\n",
       "      <th>ChapterIndex</th>\n",
       "      <th>Chapters</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Hits</th>\n",
       "      <th>Kudos</th>\n",
       "      <th>Text</th>\n",
       "      <th>Words</th>\n",
       "      <th>...</th>\n",
       "      <th>Fandom_tolkien</th>\n",
       "      <th>Fandom_shakespare</th>\n",
       "      <th>Fandom_hetalia</th>\n",
       "      <th>Fandom_attack_on_titan</th>\n",
       "      <th>Fandom_ms_paint_adventures</th>\n",
       "      <th>Fandom_marvel</th>\n",
       "      <th>Fandom_sailor_moon</th>\n",
       "      <th>Fandom_one_direction</th>\n",
       "      <th>Fandom_sherlock</th>\n",
       "      <th>History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1771</td>\n",
       "      <td>172709</td>\n",
       "      <td>Kila9Nishika</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>This is an emergency.\\xc2\\xa0 Repeat.\\xc2\\xa0 ...</td>\n",
       "      <td>2277.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2453</td>\n",
       "      <td>181007</td>\n",
       "      <td>sylvanawood</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>30.0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>29.767677</td>\n",
       "      <td>1.262626</td>\n",
       "      <td>\\nHogwarts School of Witchcraft and WizardrySt...</td>\n",
       "      <td>345.939394</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3086.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        Author  Bookmarks  ChapterIndex  Chapters  Comments  \\\n",
       "1771  172709  Kila9Nishika   0.000000           1.0         2         0   \n",
       "2453  181007   sylvanawood   0.272727          30.0        99         0   \n",
       "\n",
       "           Hits     Kudos                                               Text  \\\n",
       "1771   7.000000  1.500000  This is an emergency.\\xc2\\xa0 Repeat.\\xc2\\xa0 ...   \n",
       "2453  29.767677  1.262626  \\nHogwarts School of Witchcraft and WizardrySt...   \n",
       "\n",
       "            Words  ... Fandom_tolkien  Fandom_shakespare  Fandom_hetalia  \\\n",
       "1771  2277.000000  ...              0                  0               0   \n",
       "2453   345.939394  ...              0                  0               0   \n",
       "\n",
       "      Fandom_attack_on_titan  Fandom_ms_paint_adventures  Fandom_marvel  \\\n",
       "1771                       0                           0              0   \n",
       "2453                       0                           0              0   \n",
       "\n",
       "      Fandom_sailor_moon  Fandom_one_direction  Fandom_sherlock  History  \n",
       "1771                   0                     0                0   3298.0  \n",
       "2453                   0                     0                0   3086.0  \n",
       "\n",
       "[2 rows x 57 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv(top_tail_option + '_' + novelty_field + '_novelty_regression.tsv', sep = '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
