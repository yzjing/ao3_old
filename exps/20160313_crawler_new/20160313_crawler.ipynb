{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib2\n",
    "import re\n",
    "import csv\n",
    "from collections import OrderedDict, Counter\n",
    "import cookielib\n",
    "import time\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = 'http://archiveofourown.org/tags/Harry%20Potter%20-%20J*d*%20K*d*%20Rowling/works'\n",
    "outfile = './hp_test.csv'\n",
    "start_page = 1\n",
    "max_page = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cookie_file = './cookie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_cookie(cookie_file):\n",
    "    cookie = cookielib.MozillaCookieJar(cookie_file)\n",
    "    opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))\n",
    "    response = opener.open('http://archiveofourown.org/works/5051548?view_adult=true')\n",
    "    cookie.save(ignore_discard=True, ignore_expires=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_cookie(cookie_file):\n",
    "    cookie = cookielib.MozillaCookieJar()\n",
    "    cookie.load(cookie_file, ignore_discard=True, ignore_expires=True)\n",
    "    return cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save_cookie(cookie_file)\n",
    "cookie = load_cookie(cookie_file)\n",
    "opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_page(base_url, page_number):\n",
    "    #go to any page number.\n",
    "    return base_url+'?page=' +str(page_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_works(page):\n",
    "    #Find all works from a works list page.\n",
    "    works_page = bs(urllib2.urlopen(page))\n",
    "    links = []\n",
    "    for link in works_page.find_all('a'):\n",
    "        try:\n",
    "            url = link.get('href')\n",
    "            url_s = [i for i in url.split('/') if i != '']\n",
    "            if 'work' in url and len(url_s) == 2 and str(url_s[1]).isdigit():\n",
    "                    links.append('http://archiveofourown.org'+link.get('href'))\n",
    "        except:\n",
    "            pass\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_full_contents(url):\n",
    "    #go through adult contents filtering.\n",
    "    base = bs(urllib2.urlopen(url))\n",
    "    full_url = url\n",
    "    for link in base.find_all('a'):\n",
    "        if 'Proceed' in link.text:\n",
    "            full_url = url +'?view_adult=true'\n",
    "    return full_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_contents(url, opener=opener):\n",
    "#     get work metadata and contents from the work page.\n",
    "    try:\n",
    "        req = urllib2.Request(url)\n",
    "        page = bs(opener.open(req))\n",
    "        contents = str(page.body.text.encode('utf-8'))\n",
    "    except:\n",
    "        contents = ''\n",
    "        pass\n",
    "    return url, contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url, c = get_contents('http://archiveofourown.org/works/6633301/chapters/15177322')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1 = re.findall('Fandom:(.*?)<br />', c)\n",
    "fandom = re.findall('>(.*?)</a>', f1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sherlock (TV)']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fandom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nMain Content\\n\\n\\n\\n    While we\\'ve done our best to make the core functionality of this site accessible without javascript, it will work better with it enabled. Please consider turning it on!\\n  \\n\\n\\n\\n\\n\\nArchive of Our Own beta\\n\\n\\n\\nLog In\\n\\n\\n\\n\\nUser name:\\n\\nPassword:\\n\\n\\n\\nRemember Me\\n\\n\\n\\n\\nForgot password?\\n\\nGet an Invitation\\n\\n\\n\\n\\nSite Navigation\\n\\n\\nFandoms\\n\\nAll Fandoms\\nAnime & Manga\\nBooks & Literature\\nCartoons & Comics & Graphic Novels\\nCelebrities & Real People\\nMovies\\nMusic & Bands\\nOther Media\\nTheater\\nTV Shows\\nVideo Games\\nUncategorized Fandoms\\n\\n\\n\\nBrowse\\n\\nWorks\\nBookmarks\\nTags\\nCollections\\n\\n\\n\\nSearch\\n\\nWorks\\nBookmarks\\nTags\\nPeople\\n\\n\\n\\nAbout\\n\\nAbout Us\\nNews\\nFAQ\\nWrangling Guidelines\\nDonate or Volunteer\\n\\n\\n\\n\\nSearch Works\\n\\nWork Search:\\n\\ntip: arthur merlin words>1000 sort:hits\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\xc2\\xa0\\n\\nActions\\n\\nEntire Work\\nNext Chapter \\xe2\\x86\\x92\\n\\n\\nChapter Index\\n\\nChapter Index\\n\\n\\n\\n\\n1. To a Stranger from Another Fandom, Perhaps in So...\\n2. This Is Just To Say Stay The Hell Away From My P...\\n3. Sonnet 221B ( When in disgrace, I look upon Ben\\'...\\n4. Not Celebrating but Grieving\\n5. A Dream Within A Dream\\n6. Visit\\n\\n\\n \\nFull-page index\\n\\n\\n\\nComments \\n\\n\\nShare\\n\\nCopy and paste the following code to link back to this work (CTRL A/CMD A will select all), or use the Tweet or Tumblr links to share the work on your Twitter or Tumblr account.\\n\\n<a href=\"http://archiveofourown.org/works/6521431\"><strong>The Fact of a 221B Doorframe: A Collection of Sherlock-Related Poems</strong></a> (1829 words) by <a href=\"http://archiveofourown.org/users/Iwantthatcoat\"><strong>Iwantthatcoat</strong></a><br />Chapters: 6/?<br />Fandom: <a href=\"http://archiveofourown.org/tags/Sherlock%20-%20Fandom\">Sherlock - Fandom</a>, <a href=\"http://archiveofourown.org/tags/Sherlock%20Holmes%20*a*%20Related%20Fandoms\">Sherlock Holmes &amp; Related Fandoms</a>, <a href=\"http://archiveofourown.org/tags/Sherlock%20(TV)\">Sherlock (TV)</a><br />Rating: Teen And Up Audiences<br />Warnings: No Archive Warnings Apply<br />Relationships: Sherlock Holmes/John Watson<br />Characters: John Watson, Sherlock Holmes, Mary Morstan<br />Summary: <p>Famous poems redone in Sherlock themes.<br />(This will expand in the future, so I am creating a separate area to gather them all)<br />Billy Collins, William Carlos Williams, William Shakespeare, Stevie Smith, Adrienne Rich</p>\\n\\n\\n\\n\\n        Tweet\\n      \\n\\n\\n\\n        Share on Tumblr\\n      \\n\\n\\n\\n\\n\\nDownload\\n\\nMOBI\\nEPUB\\nPDF\\nHTML\\n\\n\\n\\n\\nWork Header\\n\\n\\n\\n              Rating:\\n          \\n\\n\\nTeen And Up Audiences\\n\\n\\n\\nArchive Warning:\\n          \\n\\n\\nNo Archive Warnings Apply\\n\\n\\n\\n              Category:\\n          \\n\\n\\nM/M\\n\\n\\n\\n              Fandoms:\\n          \\n\\n\\nSherlock - FandomSherlock Holmes & Related FandomsSherlock (TV)\\n\\n\\n\\n              Relationship:\\n          \\n\\n\\nSherlock Holmes/John Watson\\n\\n\\n\\n              Characters:\\n          \\n\\n\\nJohn WatsonSherlock HolmesMary Morstan\\n\\n\\n\\n        Language:\\n      \\n\\n        English\\n      \\nStats:\\n\\n\\nPublished:2016-04-11Updated:2016-05-05Words:1829Chapters:6/?Comments:14Kudos:6Bookmarks:2Hits:72\\n\\n\\n\\n\\n\\n\\n\\n      The Fact of a 221B Doorframe: A Collection of Sherlock-Related Poems\\n    \\n\\nIwantthatcoat\\n\\n\\nSummary:\\n\\nFamous poems redone in Sherlock themes.(This will expand in the future, so I am creating a separate area to gather them all)Billy Collins, William Carlos Williams, William Shakespeare, Stevie Smith, Adrienne Rich\\n\\n\\n\\nNotes:\\n\\nThis is my version of Billy Collins\\xe2\\x80\\x99s poem \\xe2\\x80\\x9cTo a Stranger Born in Some Distant Country Hundreds of Years from Now\\xe2\\x80\\x9d (his first\\xe2\\x80\\xa6 then my version.)And if you haven\\'t read Billy Collins, or think poetry inaccessible, go pick up one of his books ASAP.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nChapter 1: To a Stranger from Another Fandom, Perhaps in Some Distant Country, Reading at This Very Moment\\n    \\n\\n\\n\\n\\nChapter Text\\n\\xe2\\x80\\x9cTo a Stranger Born in Some Distant Country Hundreds of Years from Now\\xe2\\x80\\x9d\\n\\xe2\\x80\\x9cI write poems for a stranger who will be born in some distant country hundreds of years from now.\\xe2\\x80\\x9d -Mary Oliver\\nNobody here likes a wet dog.\\nNo one wants anything to do with a dog\\nthat is wet from being out in the rain\\nor retrieving a stick from a lake.\\nLook how she wanders around the crowded pub tonight\\ngoing from one person to another\\nhoping for a pat on the head, a rub behind the ears,\\nsomething that could be given with one hand\\nwithout even wrinkling the conversation.\\nBut everyone pushes her away,\\nsome with a knee, others with the sole of a boot.\\nEven the children, who don\\xe2\\x80\\x99t realize she is wet\\nuntil they go to pet her,\\npush her away\\nthen wipe their hands on their clothes.\\nAnd whenever she heads toward me,\\nI show her my palm, and she turns aside.\\nO stranger of the future!\\nO inconceivable being!\\nwhatever the shape of your house,\\nhowever you scoot from place to place,\\nno matter how strange and colorless the clothes you may wear,\\nI bet nobody there likes a wet dog either,\\nI bet everybody in your pub,\\neven the children, pushes her away.\\n\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94\\xe2\\x80\\x94-\\n\\xe2\\x80\\x9cTo a Stranger from Another Fandom, Perhaps in Some Distant Country, Reading at This Very Moment\\xe2\\x80\\x9d\\nNobody here likes Anderson.\\nNo one wants anything to do with a forensic investigator\\nwho is incapable of drawing correct conclusions\\nor accurate observations.\\nLook how he wanders around the crime scene tonight\\ngoing from one detective to another\\nhoping for a pat on the back, a nod of the head,\\nsomething that could be given with one hand\\nwithout even wrinkling the conversation.\\nBut everyone pushes him away,\\nsome with a closing door, others with a turn of the head.\\nEven the minor characters, who don\\xe2\\x80\\x99t realize he lowers the IQ of the entire street\\nuntil they go to talk to him,\\npush him away\\nthen shake their heads in disgust.\\nAnd if he would head towards me,\\nI would show him the back of my hand, and he would turn aside.\\nO stranger who does not watch Sherlock!\\nO inconceivable being!\\nWhatever the theme of your fandom,\\nhowever you regenerate from season to season,\\nno matter how medieval or flannel the clothes you may wear,\\nI bet nobody there likes Anderson either.\\nI bet everybody on your show,\\neven the minor characters, push him away.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nActions\\n\\n\\xe2\\x86\\x91 Top\\nNext Chapter \\xe2\\x86\\x92\\n\\n\\n\\n\\n\\n \\nComments (2)\\n\\n\\nComments\\n\\n\\nnightsky, thanangst, AugustaAugustus18, and DaringD\\n             as well as \\n          2 guests\\n         left kudos on this work!\\n        \\n(collapse)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPost Comment\\n\\nNote:\\nAll fields are required. Your email address will not be published.\\nName: \\n\\n\\nvar validation_for_comment_name_for_14919850=new LiveValidation(\\'comment_name_for_14919850\\',{wait:500,onlyOnBlur:false});validation_for_comment_name_for_14919850.add(Validate.Presence,{\"failureMessage\":\"Please enter your name.\",\"validMessage\":\"\"});\\n\\nEmail: \\n\\n\\nvar validation_for_comment_email_for_14919850=new LiveValidation(\\'comment_email_for_14919850\\',{wait:500,onlyOnBlur:false});validation_for_comment_email_for_14919850.add(Validate.Presence,{\"failureMessage\":\"Please enter your email address.\",\"validMessage\":\"\"});\\n\\n\\n\\nComment\\n\\n\\n\\n\\n4300 characters left\\nvar validation_for_comment_content_for_14919850=new LiveValidation(\\'comment_content_for_14919850\\',{wait:500,onlyOnBlur:false});validation_for_comment_content_for_14919850.add(Validate.Presence,{\"failureMessage\":\"Brevity is the soul of wit, but we need your comment to have text in it.\",\"validMessage\":\"\"});validation_for_comment_content_for_14919850.add(Validate.Length,{\"maximum\":\"4300\",\"tooLongMessage\":\"must be less than 4300 characters long.\"});\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFooter\\n\\n\\nAbout the Archive\\n\\nSite Map\\nDiversity Statement\\nTerms of Service\\nDMCA Policy \\n\\n\\n\\nContact Us\\n\\nReport Abuse\\nTechnical Support and Feedback\\n\\n\\n\\nDevelopment\\n\\notwarchive v0.9.131.3\\nKnown Issues\\nGPL by the OTW\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nif(typeof jQuery==\\'undefined\\'){document.write(unescape(\"%3Cscript src=\\'/javascripts/jquery.min.js\\' type=\\'text/javascript\\'%3E%3C/script%3E\"));document.write(unescape(\"%3Cscript src=\\'/javascripts/jquery-ui.min.js\\' type=\\'text/javascript\\'%3E%3C/script%3E\"));}\\n$j=jQuery.noConflict();\\neval(mod_pagespeed_UPau9qmizj);\\neval(mod_pagespeed_Nb$$lhlUHU);\\neval(mod_pagespeed_YFfzyWBHBy);\\neval(mod_pagespeed_HDLfjTh7jD);\\neval(mod_pagespeed_5qgono0OBM);\\neval(mod_pagespeed_dLs1YFPwmA);\\neval(mod_pagespeed_yipyx8CSiV);\\neval(mod_pagespeed_kmVBW1MKKt);\\neval(mod_pagespeed_1F8KjjRLkY);\\neval(mod_pagespeed_THGo5DXX$d);\\neval(mod_pagespeed_pZye6de$a1);\\n\\nvar name_id=\"#comment_name_for_14919850\";var email_id=\"#comment_email_for_14919850\";if(!$j(name_id).val()){$j(name_id).val($j.cookie(\\'comment_name\\'));}\\nif(!$j(email_id).val()){$j(email_id).val($j.cookie(\\'comment_email\\'));}\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_comments_time(url, opener=opener):\n",
    "    #go to the comments page of the work and find the timestamps for the comments\n",
    "    #returns a dict of {month:# of comments in the month}\n",
    "    req = urllib2.Request(url)\n",
    "    page = bs(opener.open(req))\n",
    "    times = []\n",
    "    month_dict = {'Jan':'01', 'Feb':'02','Mar':'03', 'Apr':'04', 'May':'05', 'Jun':'06', 'Jul':'07', 'Aug':'08', 'Sep':'09', 'Oct':'10', 'Nov':'11', 'Dec':'12'}\n",
    "    for line in str(page).split('<span class=\"posted datetime\">'):\n",
    "        month = re.findall('Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec', line)[0]\n",
    "        year = re.findall('<span class=\"year\">([0-9]*)</span>', line)\n",
    "        if month != [] and year != []:\n",
    "            times.append(str(year[0]) + '-' + month_dict.get(month))\n",
    "    c = Counter(times)\n",
    "    times_dict = {time:c[time] for time in times}\n",
    "    return times_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bookmarks_time(url, opener=opener):\n",
    "    #go to the bookmarks page of the work and find the timestamps for the bookmarks\n",
    "    #returns a dict of {month:# of bookmarks in the month}\n",
    "\n",
    "    req = urllib2.Request(url)\n",
    "    page = bs(opener.open(req))\n",
    "    page_list = [i for i in re.findall('<a href=\"(.*?)>', str(page)) if 'bookmarks?' in i]\n",
    "    page_list = sorted(list(set([i.split()[0].replace('\\\"', '') for i in page_list])))       \n",
    "        \n",
    "    dt = re.findall('<p class=\"datetime\">(.*?)</p>', str(page))\n",
    "    times = []\n",
    "    month_dict = {'Jan':'01', 'Feb':'02','Mar':'03', 'Apr':'04', 'May':'05', 'Jun':'06', 'Jul':'07', 'Aug':'08', 'Sep':'09', 'Oct':'10', 'Nov':'11', 'Dec':'12'}\n",
    "    for time in dt:\n",
    "        times.append(time.split()[2] + '-' + month_dict.get(time.split()[1]))\n",
    "    times = times[1:]\n",
    "    if page_list != []:\n",
    "        for page in page_list:\n",
    "            times += get_bookmarks_time_subpages('http://archiveofourown.org'+page, opener=opener)\n",
    "        \n",
    "    c = Counter(times)\n",
    "    times_dict = {time:c[time] for time in times}\n",
    "    return times_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bookmarks_time_subpages(url, opener=opener):\n",
    "    #A work's bookmarks can take up multiple pages. In this case, all timestamp information is add to the first page.\n",
    "    req = urllib2.Request(url)\n",
    "    page = bs(opener.open(req))\n",
    "    dt = re.findall('<p class=\"datetime\">(.*?)</p>', str(page))\n",
    "    times = []\n",
    "    month_dict = {'Jan':'01', 'Feb':'02','Mar':'03', 'Apr':'04', 'May':'05', 'Jun':'06', 'Jul':'07', 'Aug':'08', 'Sep':'09', 'Oct':'10', 'Nov':'11', 'Dec':'12'}\n",
    "    for time in dt:\n",
    "        times.append(time.split()[2] + '-' + month_dict.get(time.split()[1]))\n",
    "    times = times[1:]\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_header(outfile):\n",
    "    f = open(outfile, 'a')\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    keys = ['AdditionalTags', 'ArchiveWarnings', 'Author', 'Bookmarks', 'Category', 'ChapterIndex', 'Chapters', 'Characters',\\\n",
    "             'Comments', 'CompleteDate', 'Fandoms', 'Hits', 'Kudos', 'Language', 'Notes', 'PublishDate', 'Rating',\\\n",
    "             'Relationship', 'Summary', 'Text', 'Title', 'UpdateDate', 'Words']\n",
    "    writer.writerow(keys)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_work_content(work_dict,outfile):\n",
    "    #write work metadata and contents as values of a sorted dictionary.\n",
    "    f = open(outfile, 'a')\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(OrderedDict(sorted(work_dict.items())).values())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creates dictionary for information in a single work.\n",
    "def create_work_dict(url, contents):\n",
    "#     get work metadata and contents into a dictionary.\n",
    "\n",
    "    work = {}\n",
    "    \n",
    "    try:\n",
    "        rating = re.findall('Rating:(.*?)<br />',contents) \n",
    "        warning = re.findall('Warnings:(.*?)<br />',contents)\n",
    "        f1 = re.findall('Fandom:(.*?)<br />', contents)\n",
    "        fandom = re.findall('>(.*?)</a>', f1[0])        \n",
    "        category = re.findall(r'Categories:\\\\n          \\\\n\\\\n\\\\n(.*?)\\\\n\\\\n\\\\n\\\\n|Category:\\\\n          \\\\n\\\\n\\\\n(.*?)\\\\n\\\\n\\\\n\\\\n',contents)\n",
    "        relationship = re.findall('Relationships:(.*?)<br />',contents)\n",
    "        characters = re.findall('Characters:(.*?)<br />',contents)\n",
    "        additional = re.findall('Additional Tags:(.*?)<br />',contents)\n",
    "        language = re.findall(r'Language:\\\\n      \\\\n\\\\n        (.*?)\\\\n      \\\\n',contents)\n",
    "        author = re.findall(r'<strong>(.*?)</strong>',contents)[1]\n",
    "        text = re.findall(r'Work Text:(.*?)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n|Chapter Text\\\\n(.*?)\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n|Chapter Text\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n(.*?)',contents)\n",
    "        text = [i for i in text[0] if i != ''] if text != [] else []\n",
    "        title = re.findall(r'<strong>(.*?)</strong>',contents)[0]\n",
    "        summary = re.findall('>Summary: <p>(.*?)</p>',contents)\n",
    "        notes = re.findall(r'Notes:\\\\n\\\\n(.*?)\\\\n\\\\n',contents)\n",
    "        publishdate = re.findall('Published:([0-9]*-[0-9]*-[0-9]*)',contents)\n",
    "        completedate = re.findall('Completed:([0-9]*-[0-9]*-[0-9]*)',contents)\n",
    "        updatedate = re.findall('Updated:([0-9]*-[0-9]*-[0-9]*)',contents)\n",
    "        words = re.findall('Words:([0-9]*)',contents)\n",
    "        chapters = re.findall('Chapters:([0-9]*/[0-9]*)',contents)\n",
    "        kudos = re.findall('Kudos:([0-9]*)',contents)\n",
    "        hits = re.findall('Hits:([0-9]*)',contents)  \n",
    "        comments = re.findall('Comments:([0-9]*)',contents)\n",
    "        bookmarks = re.findall('Bookmarks:([0-9]*)',contents)\n",
    "\n",
    "\n",
    "        work['Rating'] = rating[0] if rating != [] else ''\n",
    "        work['ArchiveWarnings'] = warning[0] if warning != [] else ''\n",
    "        work['Fandoms'] = [i for i in fandom[0] if i != ''][0] if fandom != [] else ''\n",
    "        work['Category'] = [i for i in category[0] if i != ''][0] if category != [] else ''\n",
    "        work['Relationship'] = relationship[0] if relationship != [] else '' \n",
    "        work['Characters'] = characters[0] if characters != [] else ''\n",
    "        work['AdditionalTags'] = additional[0] if additional != [] else ''\n",
    "        work['Language'] = language[0] if language != [] else ''\n",
    "        work['Author'] = author\n",
    "        work['Text']= text[0] if text != [] else ''\n",
    "        work['Title']  = title\n",
    "        work['Summary'] = summary[0] if summary != [] else ''\n",
    "        work['Notes'] = notes[0] if notes != [] else ''\n",
    "        work['PublishDate'] = publishdate[0] if publishdate != [] else ''\n",
    "        work['CompleteDate'] = completedate[0] if completedate != [] else ''\n",
    "        work['UpdateDate'] = updatedate[0] if updatedate != [] else ''\n",
    "        work['Words'] = words[0] if words != [] else ''\n",
    "        work['Chapters'] = chapters[0] if chapters != [] else ''\n",
    "        work['Kudos'] = kudos[0] if kudos != [] else ''\n",
    "        work['Hits'] = hits[0] if hits != [] else ''\n",
    "        work['Comments'] = comments[0] if comments != [] else ''\n",
    "        work['Bookmarks'] = bookmarks[0] if bookmarks != [] else ''\n",
    "\n",
    "        #For a single-chapter work, there is no complete date. In this case, fill in with publish date.\n",
    "        if len(work['Chapters']) > 2:\n",
    "            if work['Chapters'][2]== '1':\n",
    "                work['CompleteDate'] = work['PublishDate']\n",
    "\n",
    "        #Find comments-timestamps for single-chapter work.\n",
    "        if work['Comments'] > 0 and 'works' in url:\n",
    "            id = [i for i in re.findall('[0-9]*', url) if i != ''][0]\n",
    "            comments_url = 'http://archiveofourown.org/comments/show_comments?work_id=' + str(id) \n",
    "            work['Comments'] = get_comments_time(comments_url, opener=opener)\n",
    "            if work['Comments'] == {}:\n",
    "                work['Comments'] = ''\n",
    "            \n",
    "        #Find comments-timestamps for multi-chapter work.\n",
    "        if work['Comments'] > 0 and 'chapters' in url:\n",
    "            id = [i for i in re.findall('[0-9]*', url) if i != ''][1]\n",
    "            comments_url = 'http://archiveofourown.org/comments/show_comments?chapter_id=' + str(id) \n",
    "            work['Comments'] = get_comments_time(comments_url, opener=opener)\n",
    "            if work['Comments'] == {}:\n",
    "                work['Comments'] = ''\n",
    "        \n",
    "        #Find bookmarks-timestamps for all works.\n",
    "        if work['Bookmarks'] > 0:\n",
    "            id = [i for i in re.findall('[0-9]*', url) if i != ''][0]        \n",
    "            bookmarks_url = 'http://archiveofourown.org/works/' + id + '/bookmarks'\n",
    "            work['Bookmarks'] = get_bookmarks_time(bookmarks_url)\n",
    "            if work['Bookmarks'] == {}:\n",
    "                work['Bookmarks'] = ''\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    return work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# content = get_contents('http://archiveofourown.org/works/5772715/chapters/13303756')\n",
    "# w =  create_work_dict('http://archiveofourown.org/works/5772715/chapters/13303756', str(content))\n",
    "# for i in w:\n",
    "#     print i, w[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_chapters_list(url,opener=opener):\n",
    "    #Find chapters urls and publish time for the chapter by going to the navigate page.\n",
    "    #Returns tuple (chapter url, time)\n",
    "    url_full = show_full_contents(url)\n",
    "    chapters_list = []\n",
    "    navigate = ''\n",
    "    \n",
    "    req = urllib2.Request(url_full)\n",
    "    page = bs(opener.open(req))\n",
    "    for link in page.find_all('a'):\n",
    "        if 'Chapter Index' in link.text and len(link.get('href')) > 1:\n",
    "            navigate = 'http://archiveofourown.org' + link.get('href')\n",
    "    \n",
    "    if navigate != '':\n",
    "        req2 = urllib2.Request(navigate)\n",
    "        page2 = bs(opener.open(req2))\n",
    "#         print page2\n",
    "        \n",
    "        links = re.findall('<li><a href=\"(.*?)</span></li>', str(page2))\n",
    "        for i in links:\n",
    "            chapter_url = 'http://archiveofourown.org' + i.split('\\\"')[0]\n",
    "            chapter_index = re.findall('[0-9]+\\.', i) [0].replace('.', '')\n",
    "            chapter_time = re.findall('<span class=\"datetime\">\\((.*?)\\)', i)[0]\n",
    "            chapters_list.append((chapter_url, chapter_index, chapter_time))\n",
    "            \n",
    "    return chapters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get_chapters_list('http://archiveofourown.org/works/5687074/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_single_work(url):\n",
    "    #Retrieve information from single-chapter work\n",
    "    url_full = show_full_contents(url)\n",
    "    c = get_contents(url_full)\n",
    "    work = create_work_dict(url_full, str(c))\n",
    "    work['ChapterIndex'] = ''\n",
    "    write_work_content(work,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_chapter(url, idx, time):\n",
    "    #Retrieve information from multi-chapter work. \n",
    "    #In this case, the publish time is replaced with the publish time for each chapter, but the complete time\n",
    "    #and update time is still for the work as a whole.\n",
    "    url_full = show_full_contents(url)\n",
    "    c = get_contents(url_full)\n",
    "    work = create_work_dict(url_full, str(c))\n",
    "    work['PublishDate'] = time\n",
    "    work['ChapterIndex'] = idx\n",
    "    write_work_content(work,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s = get_bookmarks_time('http://archiveofourown.org/works/5951704/bookmarks')\n",
    "# sum(s.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_next_chapter('http://archiveofourown.org/works/3078407?view_adult=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# s = get_contents('http://archiveofourown.org/works/5051548?view_adult=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# d = create_work_dict('u',str(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# d = create_work_dict('http://archiveofourown.org/works/5205566',str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# c = bs(urllib2.urlopen('http://archiveofourown.org/works/5051548?view_adult=true'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# req2 = urllib2.Request('http://archiveofourown.org/works/5051548/navigate')\n",
    "# page2 = bs(opener.open(req2))\n",
    "# for link in page2.find_all('a'):\n",
    "#     if 'Chapter' in link.text:\n",
    "#         print link.text, link.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ch = get_chapters_list('http://archiveofourown.org/works/5144414/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#main loop\n",
    "def run_scraper():\n",
    "    write_header(outfile)\n",
    "    start_time = time.time()\n",
    "    count = 0\n",
    "\n",
    "    for i in range(start_page, max_page+1):\n",
    "        print 'start crawling page:', i\n",
    "        page = find_page(start, i)\n",
    "        worklist = find_works(page)\n",
    "        for w in worklist:\n",
    "            ch_list_time = get_chapters_list(w)\n",
    "            if ch_list_time != []:\n",
    "                for ch in ch_list_time:\n",
    "                    ch_url = ch[0]\n",
    "                    ch_idx = ch[1]\n",
    "                    ch_time = ch[2]\n",
    "                    read_chapter(ch_url, ch_idx, ch_time)\n",
    "            else:\n",
    "                read_single_work(w)\n",
    "            count += 1\n",
    "\n",
    "        print 'finished crawling page:', i\n",
    "#     except:\n",
    "#         print 'unable to read work'\n",
    "#         time.sleep(5)\n",
    "#         pass\n",
    "\n",
    "#     print 'Saved %s works from %s pages of tag %s in %s seconds .' %(count, i, 'Sherlock Holmes', str(time.time() - start_time))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cProfile.run('run_scraper()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
