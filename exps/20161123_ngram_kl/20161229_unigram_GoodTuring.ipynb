{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('../../util/')\n",
    "import sgt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: add stemming; modify KL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a corpus to give to sklearn\n",
    "def create_corpus_for_voc(df):\n",
    "    doc = []\n",
    "    for i in df.Text.tolist():\n",
    "        #Remove some non-ascii characters and 'aa's\n",
    "        i = re.sub(r'aA|aa', 'a', i)\n",
    "        i = re.sub(r'\\\\xe2........|\\\\xc|\\\\xa|\\\\n|[0123456789*_]', '', i)\n",
    "        i = i.lower()\n",
    "        doc.append(i)  \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a vocabulary using sklearn's filtering\n",
    "def get_voc(corpus, ngram, mindf):\n",
    "    vectorizer = CountVectorizer(stop_words='english', ngram_range=(ngram,ngram),min_df=mindf)\n",
    "    f = vectorizer.fit_transform(corpus)\n",
    "    return set(sorted(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute unigram-frequency dict using the same preprocessing, using only words from the vocabulary\n",
    "def create_unigram_freq_dict(df):\n",
    "    text = []\n",
    "    for line in df.Text.tolist():\n",
    "        line = re.sub(r'aA|aa', 'a', line)\n",
    "        line = re.sub(r'\\\\xe2........|\\\\xc|\\\\xa|\\\\n|[0123456789*_]', '', line).lower()\n",
    "        line = re.findall(u'(?u)\\\\b\\\\w\\\\w+\\\\b', line)\n",
    "        line = [word for word in line if word in vocal]\n",
    "        text.append(dict(Counter(line)))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_timelist(df):\n",
    "    timelist = df.PublishDate.drop_duplicates().tolist()\n",
    "    timelist = [str(i)[:7] for i in timelist]\n",
    "    return sorted(list(set(timelist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_df_time(df, time):\n",
    "    return df[df.PublishDate.str[:7] == time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate unigram probabilities by simple Good Turing smoothing.\n",
    "# imput: unigram-freq dict\n",
    "# output: unigram-prob dict, mimic of a document-term matrix\n",
    "# if unigram is in this doc, prob = the unigram prob calculated by sgt\n",
    "# otherwise, prob = the probability given to \"all unknown unigrams\" by sgt\n",
    "def calc_sgt(line_dict, voc):\n",
    "    prob_line = {}\n",
    "    sgt_line = sgt.simpleGoodTuringProbs(line_dict)\n",
    "    for word in voc:\n",
    "        if word in line_dict.keys():\n",
    "            prob_line[word] = sgt_line[0][word]\n",
    "        else:\n",
    "            prob_line[word] = sgt_line[1]\n",
    "    return prob_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0 = 0.145455\n",
      "Regression: log(z) = -1.792780*log(r) + 2.487985\n",
      "{u'dont': 0.046691343314315389, u'just': 0.046691343314315389, u'people': 0.046691343314315389, u'held': 0.01128530849161225, u'want': 0.01128530849161225, u'ground': 0.046691343314315389, u'little': 0.065523294406337265, u'said': 0.23965806652986796, u'away': 0.046691343314315389, u'flying': 0.01128530849161225, u'lot': 0.01128530849161225, u'white': 0.14545454545454545, u'really': 0.01128530849161225, u'way': 0.01128530849161225, u'hand': 0.046691343314315389, u'asked': 0.028352567846030411, u'know': 0.028352567846030411, u'hands': 0.028352567846030411, u'like': 0.065523294406337265, u'youre': 0.028352567846030411, u'theyre': 0.01128530849161225, u'think': 0.01128530849161225}\n",
      "p0 = 0.113208\n",
      "Regression: log(z) = -1.637328*log(r) + 2.366825\n",
      "{u'dont': 0.049937888164122854, u'just': 0.030884315824223137, u'people': 0.0128552654751135, u'held': 0.0128552654751135, u'want': 0.0128552654751135, u'ground': 0.0128552654751135, u'little': 0.089010542149429731, u'said': 0.20808694737396982, u'away': 0.0128552654751135, u'flying': 0.030884315824223137, u'lot': 0.11320754716981132, u'white': 0.089010542149429731, u'really': 0.049937888164122854, u'way': 0.0128552654751135, u'hand': 0.030884315824223137, u'asked': 0.030884315824223137, u'know': 0.11320754716981132, u'hands': 0.11320754716981132, u'like': 0.049937888164122854, u'youre': 0.069379696529071291, u'theyre': 0.030884315824223137, u'think': 0.049937888164122854}\n",
      "p0 = 0.400000\n",
      "Regression: log(z) = -1.799675*log(r) + 1.756908\n",
      "{u'dont': 0.018777875292228709, u'just': 0.047270138182592687, u'people': 0.4, u'held': 0.4, u'want': 0.4, u'ground': 0.018777875292228709, u'little': 0.4, u'said': 0.27041083252993475, u'away': 0.018777875292228709, u'flying': 0.4, u'lot': 0.018777875292228709, u'white': 0.047270138182592687, u'really': 0.4, u'way': 0.4, u'hand': 0.047270138182592687, u'asked': 0.018777875292228709, u'know': 0.018777875292228709, u'hands': 0.018777875292228709, u'like': 0.018777875292228709, u'youre': 0.018777875292228709, u'theyre': 0.018777875292228709, u'think': 0.4}\n",
      "p0 = 0.382353\n",
      "Regression: log(z) = -2.005178*log(r) + 2.380638\n",
      "{u'dont': 0.013368511361803294, u'just': 0.013368511361803294, u'people': 0.013368511361803294, u'held': 0.013368511361803294, u'want': 0.035702506112245014, u'ground': 0.38235294117647056, u'little': 0.013368511361803294, u'said': 0.1906972149998532, u'away': 0.38235294117647056, u'flying': 0.013368511361803294, u'lot': 0.013368511361803294, u'white': 0.013368511361803294, u'really': 0.013368511361803294, u'way': 0.013368511361803294, u'hand': 0.085766944143829127, u'asked': 0.035702506112245014, u'know': 0.013368511361803294, u'hands': 0.013368511361803294, u'like': 0.035702506112245014, u'youre': 0.013368511361803294, u'theyre': 0.38235294117647056, u'think': 0.060284733639669352}\n"
     ]
    }
   ],
   "source": [
    "kl_all = []\n",
    "t0 = time()\n",
    "min_df = 3\n",
    "timelist = create_timelist(df)\n",
    "for t in timelist:\n",
    "    df_t = create_df_time(df, t)\n",
    "    # len(df_t) must > min_df\n",
    "    # tune this for filtering?\n",
    "    if len(df_t) > min_df:\n",
    "        corp = create_corpus_for_voc(df_t)\n",
    "        vocab = get_voc(corp,1,min_df)\n",
    "        unigram_dict = create_unigram_freq_dict(df_t)\n",
    "        for i in unigram_dict:\n",
    "            print(calc_sgt(i, vocab))\n",
    "    break\n",
    "        \n",
    "#         kl_month = []\n",
    "#         for row in m.toarray():\n",
    "#             kl = calc_kl(row, std)\n",
    "#             if not np.isnan(kl):\n",
    "#                 kl_month.append(kl)\n",
    "#         kl_all.append(np.average(kl_month))\n",
    "# print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/shakespare_william_works_preprocessed.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_kl(p, q):\n",
    "    return sum([p[i]*(np.log2(p[i]/q[i])) for i in range(len(p))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
