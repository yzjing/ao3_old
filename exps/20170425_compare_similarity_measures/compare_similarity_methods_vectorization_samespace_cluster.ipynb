{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create corpus from the same author and same-size random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/shakespare_william_works_preprocessed.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "au_list = ['AuburnRed',\n",
    " 'rthstewart',\n",
    " 'Jojoinabox',\n",
    " 'literarypeerelief',\n",
    " 'Lady_Loki',\n",
    " 'Shayheyred',\n",
    " 'literarypeerelief',\n",
    " 'Mangaluva',\n",
    " 'rthstewart',\n",
    " 'RandomRavenclaw9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = []\n",
    "for au in au_list:\n",
    "    df_Au = df[df.Author == au]\n",
    "    df_all.append(df_Au)   \n",
    "df_all = pd.concat(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_cnt = 0\n",
    "word_cnt = 0\n",
    "for au in au_list:\n",
    "    df_Au = df[df.Author == au]\n",
    "    df_Rand = df.sample(len(df_Au))\n",
    "\n",
    "    for doc in df_Rand.Text.tolist():\n",
    "        doc = process_sentence(doc)\n",
    "        word_cnt += len(doc)\n",
    "        doc_cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_resample(li):\n",
    "    if len(li) > 0:\n",
    "        ave_original = np.average(li)\n",
    "        aves = []\n",
    "        for i in range(1000):\n",
    "            sample = []\n",
    "            for i in range(len(li)):\n",
    "                sample.append(random.choice(li))\n",
    "            aves.append(np.average(sample))\n",
    "        tail = sorted(aves)[24]\n",
    "        head = sorted(aves)[975]\n",
    "        return (ave_original, tail, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    # input: sentence as a string\n",
    "    # output: a list of words in the sentence\n",
    "    sentence = re.sub(r'aA|aa', 'a', sentence)\n",
    "    sentence = re.sub(r'\\\\xe2........|\\\\xc|\\\\xa|\\\\n|[0123456789*_]', '', sentence).lower()\n",
    "    sentence = re.findall(u'(?u)\\\\b\\\\w\\\\w+\\\\b', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans_acc(k_means, labels):\n",
    "    prec = 0\n",
    "    for i in range(len(k_means.labels_)):\n",
    "        if k_means.labels_[i] == labels[i]:\n",
    "            prec += 1\n",
    "    prec = prec/len(k_means.labels_)\n",
    "    print(prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a corpus to give to sklearn\n",
    "def create_corpus_for_voc(df):\n",
    "    doc = []\n",
    "    for i in df.Text.tolist():\n",
    "        #Remove some non-ascii characters and 'aa's\n",
    "        i = re.sub(r'aA|aa', 'a', i)\n",
    "        i = re.sub(r'\\\\xe2........|\\\\xc|\\\\xa|\\\\n|[0123456789*_]', '', i)\n",
    "        i = i.lower()\n",
    "        doc.append(i)  \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "corpus_all = create_corpus_for_voc(df_all)\n",
    "vectorizer.fit(corpus_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "label = 0\n",
    "\n",
    "for au in au_list:\n",
    "    df_Au = df[df.Author == au]\n",
    "    corpus = create_corpus_for_voc(df_Au)\n",
    "    au_dist = vectorizer.transform(corpus).todense()\n",
    "    data.extend(au_dist.tolist())\n",
    "    labels.extend([label for i in range(len(au_dist))])\n",
    "    label += 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07834101382488479\n"
     ]
    }
   ],
   "source": [
    "k_means = cluster.KMeans(n_clusters=10)\n",
    "k_means.fit_predict(data) \n",
    "\n",
    "kmeans_acc(k_means, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a corpus to give to sklearn\n",
    "def create_sentence_list(df):\n",
    "    doc = []\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    for line in df.Text.tolist():\n",
    "        line = process_sentence(line)\n",
    "        line = [word for word in line if word not in stops]\n",
    "        doc.append(line)  \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lda_input(sentences):\n",
    "    id2word = corpora.dictionary.Dictionary(sentences)\n",
    "    corpus = [id2word.doc2bow(sentence) for sentence in sentences]\n",
    "    return id2word, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = create_sentence_list(df_all)\n",
    "id2word,corpus = create_lda_input(doc)\n",
    "lda = models.ldamodel.LdaModel(corpus=corpus,id2word=id2word,num_topics=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "label = 0\n",
    "\n",
    "for au in au_list:\n",
    "    df_Au = df[df.Author == au]\n",
    "    doc = create_sentence_list(df_Au)\n",
    "    au_dist = []\n",
    "    for i in range(len(doc)):\n",
    "        dist = lda.get_document_topics(id2word.doc2bow(doc[i]), minimum_probability = 0)\n",
    "        dist = [i[1] for i in dist]\n",
    "        au_dist.append(dist)\n",
    "    data.extend(au_dist)\n",
    "    labels.extend([label for i in range(len(au_dist))])\n",
    "    label += 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15668202764976957\n"
     ]
    }
   ],
   "source": [
    "k_means = cluster.KMeans(n_clusters=10)\n",
    "k_means.fit_predict(data) \n",
    "\n",
    "kmeans_acc(k_means, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_corpus(doc):\n",
    "    for i, line in enumerate(doc):\n",
    "        yield doc2vec.TaggedDocument(line,[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = create_sentence_list(df_all)\n",
    "corpus = list(read_corpus(doc))\n",
    "model = doc2vec.Doc2Vec(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x12a3b9160>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "label = 0\n",
    "\n",
    "for au in au_list:\n",
    "    df_Au = df[df.Author == au]\n",
    "    doc = create_sentence_list(df_Au)\n",
    "    au_dist = []\n",
    "    for doc_id in range(len(corpus)):\n",
    "        inferred_vector = model.infer_vector(corpus[doc_id].words)\n",
    "        au_dist.append(inferred_vector)\n",
    "\n",
    "    data.extend(au_dist)\n",
    "    labels.extend([label for i in range(len(au_dist))])\n",
    "    label += 1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10092165898617511\n"
     ]
    }
   ],
   "source": [
    "k_means = cluster.KMeans(n_clusters=10)\n",
    "k_means.fit_predict(data) \n",
    "\n",
    "kmeans_acc(k_means, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python35]",
   "language": "python",
   "name": "Python [python35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
