{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('../../util/')\n",
    "import sgt\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "from scipy import spatial\n",
    "from scipy.stats import entropy\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create corpus from the same author and same-size random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/shakespare_william_works_preprocessed.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_au_cnt = pd.DataFrame(df['Author'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "au_list = []\n",
    "for i in range(10):\n",
    "    au_list.append(random.choice(df_au_cnt[df_au_cnt['Author'] > 5].index.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Astray',\n",
       " 'AuburnRed',\n",
       " 'JLR',\n",
       " 'fog_shadow',\n",
       " 'grxntxire',\n",
       " 'NEStar',\n",
       " 'orphan_account',\n",
       " 'betony',\n",
       " 'yuletide_archivist',\n",
       " 'LocalSarcasm']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "au_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = []\n",
    "df_rand_dict = {}\n",
    "for au in au_list:\n",
    "    df_Au = df[df.Author == au]\n",
    "    df_all.append(df_Au)\n",
    "    df_Rand = df.sample(len(df_Au))\n",
    "    df_all.append(df_Rand)\n",
    "    df_rand_dict[au] = df_Rand    \n",
    "df_all = pd.concat(df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a corpus to give to sklearn\n",
    "def create_corpus_for_voc(df):\n",
    "    doc = []\n",
    "    for i in df.Text.tolist():\n",
    "        #Remove some non-ascii characters and 'aa's\n",
    "        i = re.sub(r'aA|aa', 'a', i)\n",
    "        i = re.sub(r'\\\\xe2........|\\\\xc|\\\\xa|\\\\n|[0123456789*_]', '', i)\n",
    "        i = i.lower()\n",
    "        doc.append(i)  \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a vocabulary using sklearn's filtering\n",
    "def get_voc(corpus, ngram, mindf):\n",
    "    vectorizer = CountVectorizer(stop_words='english', ngram_range=(ngram,ngram),min_df=mindf)\n",
    "    f = vectorizer.fit_transform(corpus)\n",
    "    return set(sorted(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_resample(li):\n",
    "    if len(li) > 0:\n",
    "        ave_original = np.average(li)\n",
    "        aves = []\n",
    "        for i in range(1000):\n",
    "            sample = []\n",
    "            for i in range(len(li)):\n",
    "                sample.append(random.choice(li))\n",
    "            aves.append(np.average(sample))\n",
    "        tail = sorted(aves)[24]\n",
    "        head = sorted(aves)[975]\n",
    "        return (ave_original, tail, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    # input: sentence as a string\n",
    "    # output: a list of words in the sentence\n",
    "    sentence = re.sub(r'aA|aa', 'a', sentence)\n",
    "    sentence = re.sub(r'\\\\xe2........|\\\\xc|\\\\xa|\\\\n|[0123456789*_]', '', sentence).lower()\n",
    "    sentence = re.findall(u'(?u)\\\\b\\\\w\\\\w+\\\\b', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_results(au_dist,rand_dist):\n",
    "    results_au = []\n",
    "    results_rand = []\n",
    "    for i in range(len(au_dist)):\n",
    "        for j in range(i, len(au_dist)):\n",
    "            results_au.append(spatial.distance.cosine(au_dist[i], au_dist[j]))\n",
    "    results_au = bootstrap_resample(results_au)\n",
    "    for i in range(len(rand_dist)):\n",
    "        for j in range(i, len(rand_dist)):\n",
    "            results_rand.append(spatial.distance.cosine(rand_dist[i], rand_dist[j]))\n",
    "    results_rand = bootstrap_resample(results_rand)\n",
    "    return results_au, results_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def JSD(P, Q):\n",
    "    _P = P / norm(P, ord=1)\n",
    "    _Q = Q / norm(Q, ord=1)\n",
    "    _M = 0.5 * (_P + _Q)\n",
    "    return 0.5 * (entropy(_P, _M) + entropy(_Q, _M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_results_jsd(au_dist,rand_dist):\n",
    "    results_au = []\n",
    "    results_rand = []\n",
    "    for i in range(len(au_dist)):\n",
    "        for j in range(i, len(au_dist)):\n",
    "            results_au.append(JSD(au_dist[i], au_dist[j]))\n",
    "    results_au = bootstrap_resample(results_au)\n",
    "    for i in range(len(rand_dist)):\n",
    "        for j in range(i, len(rand_dist)):\n",
    "            results_rand.append(JSD(rand_dist[i], rand_dist[j]))\n",
    "    results_rand = bootstrap_resample(results_rand)\n",
    "    return results_au, results_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram + no smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute unigram-frequency dict using the same preprocessing, using only words from the vocabulary\n",
    "def create_unigram_freq_dict(df, voc):\n",
    "    text = []\n",
    "    df_text = df['Text'].tolist()\n",
    "    for line in df_text:\n",
    "        line = process_sentence(line)\n",
    "        text.extend(line)\n",
    "    text = map(lambda x:x if x in voc else None, text)\n",
    "    text = dict(Counter(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prob_score(vocab, sentence, unifreq):\n",
    "    unisize = len(unifreq)\n",
    "    prob = []\n",
    "    sentence = process_sentence(sentence)\n",
    "    for word in vocab:\n",
    "        if word in sentence:\n",
    "            prob.append(unifreq.get(word, 0)/unisize)\n",
    "        else:\n",
    "            prob.append(0)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = create_corpus_for_voc(df_all)\n",
    "univocab = get_voc(corpus, 1, 1)\n",
    "unidict = create_unigram_freq_dict(df_all, univocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingy/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "results_au_all = [0,0,0]\n",
    "results_rand_all = [0,0,0]\n",
    "\n",
    "for au in au_list:\n",
    "    df_Au = df[df.Author == au]\n",
    "    df_Au['Dist'] = df_Au['Text'].map(lambda x: prob_score(univocab, x, unidict))\n",
    "    au_dist = df_Au['Dist'].tolist()\n",
    "\n",
    "    df_Rand = df_rand_dict[au]\n",
    "    df_Rand['Dist'] = df_Rand['Text'].map(lambda x: prob_score(univocab, x, unidict))\n",
    "    rand_dist = df_Rand['Dist'].tolist()\n",
    "    \n",
    "    results_au, results_rand = calc_results_jsd(au_dist,rand_dist)\n",
    "    results_au_all[0] += results_au[0]\n",
    "    results_au_all[1] += results_au[1]\n",
    "    results_au_all[2] += results_au[2]\n",
    "    results_rand_all[0] += results_rand[0]\n",
    "    results_rand_all[1] += results_rand[1]\n",
    "    results_rand_all[2] += results_rand[2]\n",
    "    \n",
    "\n",
    "results_au_all[0] = results_au_all[0]/len(au_list)\n",
    "results_au_all[1] = results_au_all[1]/len(au_list)\n",
    "results_au_all[2] = results_au_all[2]/len(au_list)\n",
    "results_rand_all[0] = results_rand_all[0]/len(au_list)\n",
    "results_rand_all[1] = results_rand_all[1]/len(au_list)\n",
    "results_rand_all[2] = results_rand_all[2]/len(au_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35293504298383621, 0.31654194552571913, 0.38528981756401942] [0.37844145322657041, 0.33627186751614874, 0.41794775616744373]\n"
     ]
    }
   ],
   "source": [
    "print(results_au_all,results_rand_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Unigram + Good-Turing smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_unigram_freq_dict(df, voc):\n",
    "    text = {}\n",
    "    df_text = df.Text.tolist()\n",
    "    for line in df_text:\n",
    "        line_f = process_sentence(line)\n",
    "        line_f = [word for word in line_f if word in voc]\n",
    "        text[line] = dict(Counter(line_f))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dist(text, di, vocab):\n",
    "    prob_line = []\n",
    "    sgt_line = sgt.simpleGoodTuringProbs(di[text])\n",
    "    num_abs_words = len(vocab - set(di[text].keys()))\n",
    "    for word in vocab:\n",
    "        if word in di[text].keys():\n",
    "            prob_line.append(sgt_line[0][word])\n",
    "        else:\n",
    "            prob_line.append(sgt_line[1]/float(num_abs_words))\n",
    "    return prob_line\n",
    "#     except:\n",
    "#         return [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = create_corpus_for_voc(df_all)\n",
    "univocab = get_voc(corpus, 1, 1)\n",
    "unidict = create_unigram_freq_dict(df_all, univocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingy/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "results_au_all_2 = [0,0,0]\n",
    "results_rand_all_2 = [0,0,0]\n",
    "\n",
    "for au in au_list:\n",
    "    df_Au = df[df.Author == au]\n",
    "    df_Au['Dist'] = df_Au['Text'].map(lambda x: get_dist(x, unidict, univocab))\n",
    "    au_dist = df_Au['Dist'].tolist()\n",
    "\n",
    "    df_Rand = df_rand_dict[au]\n",
    "    df_Rand['Dist'] = df_Rand['Text'].map(lambda x: get_dist(x, unidict, univocab))\n",
    "    rand_dist = df_Rand['Dist'].tolist()\n",
    "    \n",
    "    results_au, results_rand = calc_results_jsd(au_dist,rand_dist)\n",
    "    results_au_all_2[0] += results_au[0]\n",
    "    results_au_all_2[1] += results_au[1]\n",
    "    results_au_all_2[2] += results_au[2]\n",
    "    results_rand_all_2[0] += results_rand[0]\n",
    "    results_rand_all_2[1] += results_rand[1]\n",
    "    results_rand_all_2[2] += results_rand[2]\n",
    "    \n",
    "\n",
    "results_au_all_2[0] = results_au_all_2[0]/len(au_list)\n",
    "results_au_all_2[1] = results_au_all_2[1]/len(au_list)\n",
    "results_au_all_2[2] = results_au_all_2[2]/len(au_list)\n",
    "results_rand_all_2[0] = results_rand_all_2[0]/len(au_list)\n",
    "results_rand_all_2[1] = results_rand_all_2[1]/len(au_list)\n",
    "results_rand_all_2[2] = results_rand_all_2[2]/len(au_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16115418568008127, 0.14370050194312936, 0.17764297024189055] [0.22030305319738175, 0.19795286001959006, 0.24127330359129293]\n"
     ]
    }
   ],
   "source": [
    "print(results_au_all_2,results_rand_all_2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bigram + Stupid backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute unigram-frequency dict using the same preprocessing, using only words from the vocabulary\n",
    "def create_unigram_freq_dict(df, voc):\n",
    "    text = []\n",
    "    df_text = df.Text.tolist()\n",
    "    for line in df_text:\n",
    "        line_f = process_sentence(line)\n",
    "        text.extend(line_f)\n",
    "    text = map(lambda x:x if x in voc else None, text)\n",
    "    text = dict(Counter(text))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bigram_freq_dict(df, voc):\n",
    "    text = []\n",
    "    df_text = df.Text.tolist()\n",
    "    for line in df_text:\n",
    "        line_f = re.sub(r'aA|aa', 'a', line)\n",
    "        line_f = re.sub(r'\\\\xe2........|\\\\xc|\\\\xa|\\\\n|[0123456789*_]', '', line_f).lower()\n",
    "        line_f = re.findall(u'(?u)\\\\b\\\\w\\\\w+\\\\b', line_f)\n",
    "        text.extend(line_f)\n",
    "    text_bi = []\n",
    "    for i in range(len(text)-1):\n",
    "        text_bi.append(text[i]+' '+text[i+1]) \n",
    "    text_bi = map(lambda x:x if x in voc else None, text_bi)\n",
    "    text_bi = dict(Counter(text_bi))\n",
    "    return text_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stupid backoff. If bigram is in dictionary, score = freq/size.\n",
    "# If not, go back to unigram, score = 0.4*unigram/size.\n",
    "\n",
    "def calc_sb(bigram, bifreq, unifreq):\n",
    "    if bifreq.get(bigram):\n",
    "        return float(bifreq.get(bigram))/len(bifreq)\n",
    "    else:\n",
    "        uni = bigram.split(' ')[1]\n",
    "        return float(0.4*unifreq.get(uni, 0))/len(unifreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sb_score(bivocab, sentence, unifreq, bifreq):\n",
    "    bigrams = []\n",
    "\n",
    "    sentence = re.sub(r'aA|aa', 'a', sentence)\n",
    "    sentence = re.sub(r'\\\\xe2........|\\\\xc|\\\\xa|\\\\n|[0123456789*_]', '', sentence).lower()\n",
    "    sentence = re.findall(u'(?u)\\\\b\\\\w\\\\w+\\\\b', sentence)\n",
    "    for i in range(len(sentence)-1):\n",
    "        bigrams.append(sentence[i]+' '+sentence[i+1]) \n",
    "\n",
    "    prob = list(map(lambda x: calc_sb(x, bifreq, unifreq) if x in bigrams else 0, bivocab))\n",
    "\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = create_corpus_for_voc(df_all)\n",
    "univocab = get_voc(corpus, 1,1)\n",
    "unidict = create_unigram_freq_dict(df_all, univocab)\n",
    "bivocab = get_voc(corpus,2,1)\n",
    "bidict = create_bigram_freq_dict(df_all, bivocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingy/anaconda/envs/python35/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "results_au_all_3 = [0,0,0]\n",
    "results_rand_all_3 = [0,0,0]\n",
    "for au in au_list:\n",
    "    df_Au = df[df.Author == au]\n",
    "    df_Rand = df_rand_dict[au]\n",
    "    \n",
    "    df_Au['Dist'] = df_Au['Text'].map(lambda x: sb_score(bivocab, x, unidict, bidict))\n",
    "    au_dist = df_Au['Dist'].tolist()\n",
    "\n",
    "    df_Rand['Dist'] = df_Rand['Text'].map(lambda x: sb_score(bivocab, x, unidict, bidict))\n",
    "    rand_dist = df_Rand['Dist'].tolist()\n",
    "    \n",
    "    results_au, results_rand = calc_results_jsd(au_dist,rand_dist)\n",
    "    results_au_all_3[0] += results_au[0]\n",
    "    results_au_all_3[1] += results_au[1]\n",
    "    results_au_all_3[2] += results_au[2]\n",
    "    results_rand_all_3[0] += results_rand[0]\n",
    "    results_rand_all_3[1] += results_rand[1]\n",
    "    results_rand_all_3[2] += results_rand[2]\n",
    "    \n",
    "\n",
    "results_au_all_3[0] = results_au_all_3[0]/len(au_list)\n",
    "results_au_all_3[1] = results_au_all_3[1]/len(au_list)\n",
    "results_au_all_3[2] = results_au_all_3[2]/len(au_list)\n",
    "results_rand_all_3[0] = results_rand_all_3[0]/len(au_list)\n",
    "results_rand_all_3[1] = results_rand_all_3[1]/len(au_list)\n",
    "results_rand_all_3[2] = results_rand_all_3[2]/len(au_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54993509704506782, 0.49732690365341237, 0.59778409928982967] [0.58519413149015154, 0.53156174419394742, 0.63501826922754834]\n"
     ]
    }
   ],
   "source": [
    "print(results_au_all_3,results_rand_all_3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plt_multiple(l1_au,l1_rand,l2_au,l2_rand,l3_au,l3_rand):\n",
    "    plt.figure(figsize=(13,4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    lower_error1 = [l1_au[0] - l1_au[1]]\n",
    "    upper_error1 = [l1_au[2] - l1_au[0]]\n",
    "    lower_error2 = [l1_rand[0] - l1_rand[1]]\n",
    "    upper_error2 = [l1_rand[2] - l1_rand[0]]\n",
    "\n",
    "    asymmetric_error1 =[lower_error1,lower_error2 ]\n",
    "    asymmetric_error2 =[upper_error1, upper_error2]\n",
    "    p1 = [1, 2]\n",
    "    p2 = [l1_au[0], l1_rand[0]]\n",
    "\n",
    "    plt.errorbar(p1, p2, yerr=[asymmetric_error1, asymmetric_error2],fmt='o')\n",
    "    plt.xlim(0.5,2.5)\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xticks(p1, ['Same author', 'Multiple authors'])\n",
    "    plt.ylabel('Unigram + no smoothing', fontsize = 14)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    lower_error1 = [l2_au[0] - l2_au[1]]\n",
    "    upper_error1 = [l2_au[2] - l2_au[0]]\n",
    "    lower_error2 = [l2_rand[0] - l2_rand[1]]\n",
    "    upper_error2 = [l2_rand[2] - l2_rand[0]]\n",
    "\n",
    "    asymmetric_error1 =[lower_error1,lower_error2 ]\n",
    "    asymmetric_error2 =[upper_error1, upper_error2]\n",
    "    p1 = [1, 2]\n",
    "    p2 = [l2_au[0], l2_rand[0]]\n",
    "\n",
    "    plt.errorbar(p1, p2, yerr=[asymmetric_error1, asymmetric_error2],fmt='o')\n",
    "    plt.xlim(0.5,2.5)\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xticks(p1, ['Same author', 'Multiple authors'])\n",
    "    plt.ylabel('Unigram + Good-Turing smoothing', fontsize = 14)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    lower_error1 = [l3_au[0] - l3_au[1]]\n",
    "    upper_error1 = [l3_au[2] - l3_au[0]]\n",
    "    lower_error2 = [l3_rand[0] - l3_rand[1]]\n",
    "    upper_error2 = [l3_rand[2] - l3_rand[0]]\n",
    "\n",
    "    asymmetric_error1 =[lower_error1,lower_error2 ]\n",
    "    asymmetric_error2 =[upper_error1, upper_error2]\n",
    "    p1 = [1, 2]\n",
    "    p2 = [l3_au[0], l3_rand[0]]\n",
    "\n",
    "    plt.errorbar(p1, p2, yerr=[asymmetric_error1, asymmetric_error2],fmt='o')\n",
    "    plt.xlim(0.5,2.5)\n",
    "    plt.ylim(0,1)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xticks(p1, ['Same author', 'Multiple authors'])\n",
    "    plt.ylabel('Bigram + Stupid backoff', fontsize = 14)\n",
    "\n",
    "    plt.savefig('comparison_ngram_10au_jsd_2.pdf', type='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jingy/anaconda/envs/python35/lib/python3.5/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEGCAYAAABlxeIAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nioW0aXQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11016efd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt_multiple(results_au_all_2,results_rand_all_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python35]",
   "language": "python",
   "name": "Python [python35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
